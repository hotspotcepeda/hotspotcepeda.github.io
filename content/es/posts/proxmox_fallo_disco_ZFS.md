---
title: "Disco ZFS Fallando: Detecci贸n y Reemplazo"
date: 2025-06-15
draft: false
description: "Tutorial paso a paso sobre c贸mo detectar, identificar f铆sicamente y reemplazar un disco duro con fallos en un pool ZFS"
hideToc: false
enableToc: true
enableTocContent: false
author: HotspotCepeda 
authorEmoji: ""
tags:
  - homelab
  - privacidad
  - selfhosting
  - opensource
  - zfs
  - raid
categories:
  - Tecnolog铆a
series:
  - Homelab desde cero
libraries:
  - mermaid
image: images/feature2/nascrash.png
---

 ZFS, es un sistema de archivos robusto dise帽ado precisamente para estas situaciones. Recientemente, mi servidor comenz贸 a reportar errores en uno de los discos de mi pool.

Compartir茅 el proceso exacto que segu铆 para detectar el problema, identificar el disco f铆sico culpable y reemplazarlo de forma segura, todo sin perder un solo byte de datos.

## Paso 1: Detecci贸n del Problema con `zpool status`

El primer indicio de un problema suele venir del comando `zpool status`. Al ejecutarlo, recib铆 una salida que, aunque preocupante, me dio toda la informaci贸n necesaria para empezar.

```bash
usuario@servidor:~# zpool status mi-pool-raid10
  pool: mi-pool-raid10
 state: ONLINE
status: One or more devices has experienced an unrecoverable error.  An
        attempt was made to correct the error.  Applications are unaffected.
action: Determine if the device needs to be replaced, and clear the errors
        using 'zpool clear' or replace the device with 'zpool replace'.
   see: https://openzfs.github.io/openzfs-docs/msg/ZFS-8000-9P
  scan: scrub repaired 56.2M in 00:14:03 with 0 errors on [Fecha del escaneo]
config:

        NAME              STATE     READ WRITE CKSUM
        mi-pool-raid10    ONLINE       0     0     0
          mirror-0        ONLINE       0     0     0
            sda           ONLINE       0     0     0
            sdb           ONLINE       0     0     0
          mirror-1        ONLINE       0     0     0
            sdc           ONLINE       0     0     0
            sdd           ONLINE       0     0 3.53K

errors: No known data errors
```



**An谩lisis de la salida:**

*   **`state: ONLINE`**: 隆Buenas noticias! El pool sigue en l铆nea y funcionando.
*   **`status: One or more devices has experienced an unrecoverable error`**: Aqu铆 est谩 la alerta. Algo no va bien.
*   **`sdd ONLINE 0 0 3.53K`**: El culpable. El disco `/dev/sdd` tiene m谩s de 3.500 errores de checksum (CKSUM). Esto significa que ZFS intent贸 leer datos de 茅l, pero no coincid铆an con la suma de verificaci贸n guardada. Gracias a la redundancia del `mirror-1`, pudo corregir el error al vuelo usando los datos del disco `sdc`.
*   **`errors: No known data errors`**: Lo m谩s importante. Mis datos est谩n 铆ntegros.

Intent茅 ejecutar `zpool clear mi-pool-raid10`, pero los errores volvieron a aparecer, una se帽al inequ铆voca de que el disco ten铆a un fallo de hardware persistente. Era hora de reemplazarlo.
Otro ejemplo de errores encontrados,
```bash
usuario@server:~# zpool status zfs-raid10
  pool: zfs-raid10
 state: DEGRADED
status: One or more devices has experienced an unrecoverable error.  An
        attempt was made to correct the error.  Applications are unaffected.
action: Determine if the device needs to be replaced, and clear the errors
        using 'zpool clear' or replace the device with 'zpool replace'.
   see: https://openzfs.github.io/openzfs-docs/msg/ZFS-8000-9P
  scan: resilvered 155M in 00:00:03 with 0 errors on [Fecha del escaneo]
config:

        NAME                                      STATE     READ WRITE CKSUM
        zfs-raid10                            DEGRADED     0     0     0
          mirror-0                            DEGRADED     0     0     0
            sda                                  DEGRADED     0     0     0  too many slow I/Os
            sdb                                 ONLINE           0     0     0
          mirror-1                            DEGRADED     0     0     0
            sdc                                  DEGRADED     0     0     1  too many errors
            ata-TOSHIBA                   ONLINE          0     0     0

errors: No known data errors
usuario@server:~# zpool clear zfs-raid10
usuario@server:~# 
usuario@server:~# 
usuario@server:~# zpool status zfs-raid10
  pool: zfs-raid10
 state: ONLINE
  scan: resilvered 155M in 00:00:03 with 0 errors on [Fecha del escaneo]
config:

        NAME                                  STATE     READ WRITE CKSUM
        zfs-raid10                        ONLINE       0     0     0
          mirror-0                        ONLINE       0     0     0
            sda                              ONLINE       0     0     0
            sdb                             ONLINE       0     0     0
          mirror-1                        ONLINE       0     0     0
            sdc                              ONLINE       0     0     0
            ata-TOSHIBA               ONLINE       0     0     0

errors: No known data errors
usuario@server:~# 
```
Otro fallo de disco
```bash
usuario@servidor:~# zpool status zfs-raid10
  pool: zfs-raid10
 state: DEGRADED
status: One or more devices has experienced an unrecoverable error.  An
        attempt was made to correct the error.  Applications are unaffected.
action: Determine if the device needs to be replaced, and clear the errors
        using 'zpool clear' or replace the device with 'zpool replace'.
   see: https://openzfs.github.io/openzfs-docs/msg/ZFS-8000-9P
  scan: resilvered 155M in 00:00:03 with 0 errors on Mon Sep  8 20:38:48 2025
config:

        NAME                                  STATE     READ WRITE CKSUM
        zfs-raid10                        DEGRADED     0     0     0
          mirror-0                            DEGRADED     0     0     0
            sda                               DEGRADED     0     0    35  too many errors   <-- OJO
            sdb                               ONLINE       0     0     0
          mirror-1                            ONLINE       0     0     0
            sdc                               ONLINE       0     0    24
            ata-TOSHIBA_              ONLINE       0     0     0

errors: No known data errors
usuario@servidor:~# ^C
usuario@servidor:~# zpool clear
missing pool name
usage:
        clear [[--power]|[-nF]] <pool> [device]
usuario@servidor:~# zpool clear 
rpool           zfs-raid10  
usuario@servidor:~# zpool clear zfs-raid10 
usuario@servidor:~# 
usuario@servidor:~# 
usuario@servidor:~# zpool status zfs-raid10
  pool: zfs-raid10
 state: ONLINE
  scan: resilvered 155M in 00:00:03 with 0 errors on Mon Sep  8 20:38:48 2025
config:

        NAME                                  STATE     READ WRITE CKSUM
        zfs-raid10                        ONLINE       0     0     0
          mirror-0                            ONLINE       0     0     0
            sda                               ONLINE       0     0     0
            sdb                               ONLINE       0     0     0
          mirror-1                            ONLINE       0     0     0
            sdc                               ONLINE       0     0     0
            ata-TOSHIBA_              ONLINE       0     0     0

errors: No known data errors
usuario@servidor:~# 
```

## Paso 2: Identificaci贸n F铆sica del Disco

Saber que `/dev/sdd` es el disco problem谩tico no me ayuda a encontrarlo dentro de una caja con varios discos id茅nticos. Necesitaba un identificador 煤nico: el **n煤mero de serie**.

### M茅todo A: El N煤mero de Serie (El m谩s fiable)

La herramienta `smartctl` es perfecta para esto.

```bash
usuario@servidor:~# smartctl -i /dev/sdd
smartctl 7.3 2022-02-28 r5338 [x86_64-linux-X.X.X] (local build)
Copyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org

=== START OF INFORMATION SECTION ===
Model Family:     Seagate Enterprise Series
Device Model:     ST4000NMXXXX-XXXXXX
Serial Number:    ABC123XYZ
LU WWN Device Id: 5 000c50 0XXXXXXXX
Firmware Version: EN09
User Capacity:    4,000,787,030,016 bytes [4.00 TB]
# ... resto de la salida
```

Con el n煤mero de serie **`ABC123XYZ`** en mano, solo tuve que buscar la etiqueta en cada uno de los discos f铆sicos de mi servidor hasta encontrar el correcto.

A las 48 horas el error era ya desastroso.

```bash
usuario@servidor:~# smartctl -i /dev/sdd
smartctl 7.3 2022-02-28 r5338 [x86_64-linux-6.8.12-11-pve] (local build)
Copyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org

Short INQUIRY response, skip product id
A mandatory SMART command failed: exiting. To continue, add one or more '-T permissive' options.
usuario@servidor:~#
```
Esto pasa por comprar discos recuperados.

### Otros M茅todos de Identificaci贸n, Si tienes LED en tu NAS.

Si el n煤mero de serie no fuera accesible, existen otras t茅cnicas:

1.  **Hacer parpadear el LED del disco:** En hardware de servidor, el comando `ledctl locate=/dev/sdd` puede encender un LED de localizaci贸n en la bah铆a del disco.
2.  **Generar actividad en el disco:** Con el comando `sudo dd if=/dev/sdd of=/dev/null bs=1M` podemos forzar una lectura constante. El LED de actividad del disco culpable parpadear谩 fren茅ticamente, delatando su posici贸n. **隆Mucho cuidado al escribir este comando!**

## Paso 3: El Proceso de Reemplazo

Con el disco identificado, el proceso de reemplazo es met贸dico y seguro.

Mi estructura de RAID-10 se ve as铆:

{{< mermaid >}}
graph TD
    Pool[mi-pool-raid10] --> Mirror0[Mirror-0]
    Pool --> Mirror1[Mirror-1]
    Mirror0 --> sda[sda: Disco 1]
    Mirror0 --> sdb[sdb: Disco 2]
    Mirror1 --> sdc[sdc: Disco 3]
    Mirror1 --> sdd((sdd: Disco 4 - CON FALLOS))
{{< /mermaid >}}

1.  **Adquirir un disco de reemplazo:** Compr茅 un disco nuevo de capacidad **igual o superior** (4 TB en mi caso). Es un requisito indispensable para ZFS.

2.  **Reemplazo F铆sico:** Apagu茅 el servidor, localic茅 el disco con el n煤mero de serie `ABC123XYZ`, lo desconect茅 y lo sustitu铆 por el nuevo en la **misma bah铆a y con los mismos cables**.

3.  **Reemplazo L贸gico en ZFS:** Una vez encendido el servidor, el nuevo disco fue detectado como `/dev/sdd`. El siguiente comando le ordena a ZFS que reemplace el dispositivo "viejo" (identificado por su path) con el nuevo que ahora est谩 en su lugar.

    ```bash
    sudo zpool replace mi-pool-raid10 sdd
    ```
    Si el nuevo disco apareciera con otro nombre (ej. `/dev/sdh`), se usar铆a el ID del disco viejo: `sudo zpool replace mi-pool-raid10 [ID-del-disco-viejo] /dev/sdh`.

4.  **Monitorizar la Reconstrucci贸n (Resilvering):** ZFS inici贸 inmediatamente el proceso de "resilvering", que consiste en copiar los datos del disco sano del espejo (`sdc`) al nuevo disco. Se puede monitorizar el progreso en tiempo real.

    ```bash
    watch zpool status
    ```
    La salida mostrar谩 el porcentaje de reconstrucci贸n y el tiempo estimado. Para un disco de 4 TB, este proceso puede tardar varias horas.

Una vez finalizado el `resilver`, el pool volvi贸 a su estado `ONLINE` y saludable, sin errores y con todos los datos intactos.



---

### **Gu铆a T茅cnica: Reemplazo de un Disco Fallido en un Pool ZFS RAID10**

#### **Introducci贸n**

Este documento detalla el procedimiento completo seguido para reemplazar un disco duro fallido en un pool ZFS configurado en RAID10. El proceso abarca desde la detecci贸n inicial del fallo hasta la verificaci贸n final del estado del pool, incluyendo los imprevistos encontrados y las lecciones aprendidas. El objetivo es servir como gu铆a de mejores pr谩cticas para administradores de sistemas que enfrenten una situaci贸n similar.

---

#### **1. Detecci贸n y Diagn贸stico Inicial del Fallo**

La monitorizaci贸n proactiva del estado del pool ZFS es fundamental. El primer indicio del problema se obtuvo mediante el comando est谩ndar de estado:

```bash
# zpool status mi-pool-raid10
```

La salida fue inequ铆voca, indicando que uno de los dispositivos estaba en estado `FAULTED` debido a un n煤mero excesivo de errores de lectura/escritura y checksum.

```
  pool: mi-pool-raid10
 state: ONLINE
status: One or more devices are faulted in response to persistent errors.
...
config:
  NAME          STATE     READ WRITE CKSUM
  mi-pool-raid10  ONLINE       0     0     0
    mirror-0    ONLINE       0     0     0
      disco_sano_1 ONLINE       0     0     0
      disco_sano_2 ONLINE       0     0     0
    mirror-1    ONLINE       0     0     0
      disco_sano_3 ONLINE       0     0     0
      disco_malo  FAULTED      3    80 3.53K  too many errors
```

El pool permanec铆a `ONLINE` gracias a la redundancia del `mirror-1`, pero en un estado degradado que requer铆a acci贸n inmediata.

---

#### **2. Identificaci贸n F铆sica del Disco Defectuoso**

Un identificador l贸gico como `/dev/sdX` es ef铆mero y no fiable para la identificaci贸n f铆sica, ya que puede cambiar en cada arranque. Es imperativo utilizar un identificador persistente.

**Precauci贸n:** Nunca se debe asumir que `/dev/sdX` corresponde a una bah铆a f铆sica espec铆fica sin una verificaci贸n rigurosa.

Se emplearon dos m茅todos para la identificaci贸n inequ铆voca:

1.  **Comando `ls -l /dev/disk/by-id/`:** Este comando lista los enlaces simb贸licos persistentes a los dispositivos, incluyendo el modelo y n煤mero de serie en el nombre del enlace. Se busc贸 el enlace que apuntaba al dispositivo l贸gico `disco_malo`.

    ```bash
    # ls -l /dev/disk/by-id/
    ...
    lrwxrwxrwx 1 root root 9 Jun 17 12:00 ata-SEAGATE_MODEL_SERIALNUMBER -> ../../disco_malo
    ...
    ```

2.  **Comando `smartctl -i /dev/disco_malo`:** Se utiliz贸 para obtener directamente la informaci贸n de identidad del disco, incluyendo el n煤mero de serie. El disco fallido estaba tan degradado que este comando fall贸, confirmando la severidad del problema y reforzando la identificaci贸n obtenida con el m茅todo anterior.

Con el n煤mero de serie en mano, se procedi贸 a la localizaci贸n f铆sica del disco en el chasis del servidor.

---

#### **3. Procedimiento de Reemplazo F铆sico**

Se sigui贸 un protocolo de reemplazo "cold-swap" para minimizar riesgos:

1.  **Apagado Programado:** Se realiz贸 un apagado controlado del servidor.
2.  **Extracci贸n:** Se retir贸 el disco f铆sicamente identificado por su n煤mero de serie.
3.  **Instalaci贸n:** Se instal贸 un nuevo disco de capacidad igual o superior en la misma bah铆a, utilizando los mismos cables de datos y alimentaci贸n.
4.  **Encendido:** Se arranc贸 el servidor.

---

#### **4. Incidente Cr铆tico: Detecci贸n de Doble Fallo**

Tras el reinicio, una revisi贸n del estado del pool revel贸 una situaci贸n cr铆tica:

```
# zpool status mi-pool-raid10
...
status: One or more devices has experienced an error resulting in data corruption.
...
  mirror-1                DEGRADED
    disco_fantasma        FAULTED      ... was /dev/sdX
    disco_que_era_sano    ONLINE       ... 28.2K (CKSUM errors)
```

El disco que formaba el espejo del dispositivo reci茅n fallado (`disco_que_era_sano`) comenz贸 a registrar miles de errores de checksum (`CKSUM`). Esto indicaba un **fallo casi simult谩neo del segundo miembro del espejo**, la peor contingencia posible en un RAID1.

**Lecci贸n Aprendida:** Un fallo en un disco de un mirror ejerce una carga adicional sobre el disco restante durante la degradaci贸n y el `resilvering`. Si este segundo disco ya estaba envejecido o ten铆a problemas latentes, el riesgo de un fallo en cascada es significativo.

---

#### **5. Recuperaci贸n y Reconstrucci贸n del Pool**

La estrategia se centr贸 en estabilizar el pool y reemplazar el disco fallido original, confiando en que el segundo disco aguantar铆a el proceso de reconstrucci贸n.

1.  **Revisi贸n de Conexiones:** Se realiz贸 un nuevo ciclo de apagado para revisar y reasentar firmemente las conexiones de todos los discos, lo cual mejor贸 notablemente el estado del segundo disco afectado.
2.  **Comando de Reemplazo:** Se ejecut贸 el comando `zpool replace`, utilizando el identificador num茅rico del disco ausente y la ruta persistente (`by-id`) del nuevo disco para evitar ambig眉edades.

    ```bash
    # zpool replace mi-pool-raid10 <GUID_DISCO_AUSENTE> /dev/disk/by-id/<ID_DISCO_NUEVO>
    ```

3.  **Monitorizaci贸n del `Resilvering`:** El proceso de reconstrucci贸n se inici贸 inmediatamente. Se monitoriz贸 en tiempo real con `watch zpool status`.

    ```
    scan: resilver in progress... XX% done, HH:MM:SS to go
    ```

Al finalizar, el pool volvi贸 al estado `ONLINE`, aunque con contadores de error persistentes del incidente.

---

#### **6. Limpieza Final y Verificaci贸n de Integridad**

Para devolver el pool a un estado impecable, se siguieron dos pasos finales:

1.  **Auditor铆a de Datos (`scrub`):** Se inici贸 un `scrub` manual para forzar a ZFS a leer cada bloque de datos y verificar su integridad contra la copia redundante.

    ```bash
    # zpool scrub mi-pool-raid10
    ```

2.  **Limpieza de Errores (`clear`):** Una vez verificado que el `scrub` no reportaba errores incorregibles, se reiniciaron los contadores de errores del pool. Esto es crucial para que cualquier futuro error sea indicativo de un nuevo problema.

    ```bash
    # zpool clear mi-pool-raid10
    ```

Tras estos pasos, el comando `zpool status` finalmente report贸 un estado `ONLINE` limpio, sin errores pendientes y con todos los discos funcionando correctamente.

---

#### **7. Post-Recuperaci贸n: Estandarizaci贸n de Identificadores**

Para mejorar la robustez y legibilidad de la configuraci贸n, se procedi贸 a actualizar las referencias de los discos antiguos (que usaban `/dev/sdX`) a sus rutas persistentes `/dev/disk/by-id/`.

**Procedimiento:** Se realiz贸 un "auto-reemplazo" para cada disco, **de uno en uno**, esperando a que cada `resilver` terminara antes de proceder con el siguiente.

```bash
# zpool replace -f mi-pool-raid10 /dev/sda /dev/disk/by-id/ata-SEAGATE_MODEL_SERIAL_SDA
```
**Nota:** El flag `-f` (force) es necesario para que ZFS acepte reemplazar un disco por s铆 mismo.

Al finalizar este proceso, la configuraci贸n del pool muestra exclusivamente identificadores persistentes, haci茅ndolo inmune a cambios de nombre de dispositivo tras reinicios.

#### **Conclusi贸n**

El reemplazo de un disco en un pool ZFS, aunque te贸ricamente sencillo, puede presentar complicaciones graves. Esta experiencia subraya la importancia de:
*   **Monitorizaci贸n constante.**
*   **Identificaci贸n f铆sica precisa mediante n煤meros de serie.**
*   **Uso exclusivo de identificadores persistentes (`/dev/disk/by-id/`) en las operaciones de ZFS.**
*   **Actuar con rapidez ante el primer fallo**, ya que el riesgo de fallos en cascada es real.
*   **Mantener copias de seguridad externas y verificadas**, ya que la redundancia no es infalible.



**Reemplazo del Disco `/dev/sda`**

1.  **Identifica el disco f铆sico `sda`:**
    *   Usa `ls -l /dev/disk/by-id/` para ver los identificadores persistentes de tus discos y encontrar cu谩l apunta a `/dev/sda`. Esto te ayudar谩 a identificar el disco f铆sico correcto en tu servidor.
    *   `ls -l /dev/disk/by-id/ | grep sda`
    *   Una vez que lo tengas, busca el disco f铆sico correspondiente.

2.  **Prepara el nuevo disco:**
    *   Aseg煤rate de que el nuevo disco no contenga datos importantes ni particiones que quieras conservar.

3.  **Inicia el reemplazo del disco en ZFS:**
    *   Ejecuta el siguiente comando para decirle a ZFS que reemplace `sda` con el nuevo disco. **Aseg煤rate de que `/dev/sdX_NUEVO` sea el identificador correcto del nuevo disco (por ejemplo, `/dev/sde`, `/dev/sdf`, etc.).** Si tienes un identificador `/dev/disk/by-id/` para el nuevo disco, es m谩s seguro usarlo.

    ```bash
    sudo zpool replace zfs-raid10-8tb sda /dev/sdX_NUEVO
    ```

    *   **Ejemplo:** Si el nuevo disco se detecta como `/dev/sde`, el comando ser铆a:
        ```bash
        sudo zpool replace zfs-raid10-8tb sda /dev/sde
        ```

4.  **Monitorea el proceso de "resilver":**
    *   Despu茅s de ejecutar el comando `zpool replace`, ZFS comenzar谩 a copiar todos los datos del otro disco del espejo (`sdb`) al nuevo disco (`/dev/sdX_NUEVO`). Este proceso se llama "resilver".
    *   Puedes monitorear el progreso con:
        ```bash
        zpool status zfs-raid10-8tb
        ```
    *   Ver谩s que el pool estar谩 en estado `DEGRADED` durante el resilver (ya que un disco est谩 siendo reemplazado), y el nuevo disco aparecer谩 como "replacing". Una vez completado, el pool volver谩 a `ONLINE`.

5.  **Limpia los errores (opcional pero recomendado):**
    *   Una vez que el "resilver" haya terminado y el pool vuelva a estar `ONLINE` (sin dispositivos en estado `DEGRADED` o "replacing"), puedes limpiar los errores registrados:
        ```bash
        sudo zpool clear zfs-raid10-8tb
        ```
    *   Esto restablecer谩 el contador de errores del pool.

**Nota importante:** Aunque solo est茅s reemplazando `sda` ahora, recuerda que el disco `sdd` tiene 21 sectores reasignados, lo cual es una se帽al clara de falla. Es muy recomendable que tambi茅n planifiques su reemplazo. Tu pool estar谩 m谩s vulnerable hasta que `sdd` tambi茅n sea reemplazado o retirado si no es parte del pool principal.